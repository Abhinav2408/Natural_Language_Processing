{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "glpccXj3y5ui"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# from nltk.corpus import stopwords\n",
        "# stop_words = (stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bzdtG1zzHPs",
        "outputId": "2a655661-a137-4892-f04e-61fdec16c7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.28.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.22.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2022.9.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.0.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhi2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "4tpkiZhqzIxP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd    \n",
        "poltutrain = pd.read_json(path_or_buf=\"poltu data/train.jsonl\", lines=True)\n",
        "poltuval = pd.read_json(path_or_buf=\"poltu data/val.jsonl\", lines=True)\n",
        "\n",
        "covidtrain = pd.read_json(path_or_buf=\"covid data/train.jsonl\", lines=True)\n",
        "covidval = pd.read_json(path_or_buf=\"covid data/val.jsonl\", lines=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "poltutrain = poltutrain.drop('image',axis=1)\n",
        "poltuval = poltuval.drop('image',axis=1)\n",
        "\n",
        "covidtrain = covidtrain.drop('image',axis=1)\n",
        "covidval = covidval.drop('image',axis=1)\n",
        "\n",
        "labels = {'hero': 0,\n",
        "          'villain': 1,\n",
        "          'victim': 2,\n",
        "          'other': 3\n",
        "          }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ofBnxOfXzLaR"
      },
      "outputs": [],
      "source": [
        "contractions = { \n",
        "  \"ain't\": \"am not\",\n",
        "  \"aren't\": \"are not\",\n",
        "  \"cant\":\"cannot\",\n",
        "  \"can't\": \"cannot\",\n",
        "  \"can't've\": \"cannot have\",\n",
        "  \"'cause\": \"because\",\n",
        "  \"bc\": \"because\",\n",
        "  \"becos\":\"because\",\n",
        "  \"cause\": \"because\",\n",
        "  \"could've\": \"could have\",\n",
        "  \"couldn't\": \"could not\",\n",
        "  \"couldn't've\": \"could not have\",\n",
        "  \"corp\": \"corporation\",\n",
        "  \"cud\":\"could\",\n",
        "  \"didn't\": \"did not\",\n",
        "  \"doesn't\": \"does not\",\n",
        "  \"don't\": \"do not\",\n",
        "  \"execs\": \"executives\",\n",
        "  \"fck\": \"fuck\",\n",
        "  \"fcking\": \"fucking\",\n",
        "  \"gon na\": \"going to\",\n",
        "  \"hadn't\": \"had not\",\n",
        "  \"hadn't've\": \"had not have\",\n",
        "  \"hasn't\": \"has not\",\n",
        "  \"haven't\": \"have not\",\n",
        "  \"he'd\": \"he would\",\n",
        "  \"he'd've\": \"he would have\",\n",
        "  \"he'll\": \"he will\",\n",
        "  \"he'll've\": \"he will have\",\n",
        "  \"he's\": \"he is\",\n",
        "  \"how'd\": \"how did\",\n",
        "  \"how'd'y\": \"how do you\",\n",
        "  \"how'll\": \"how will\",\n",
        "  \"how's\": \"how is\",\n",
        "  \"im\": \"i am\",\n",
        "  \"iam\": \"i am\",\n",
        "  \"i'd\": \"I would\",\n",
        "  \"i'd've\": \"I would have\",\n",
        "  \"i'll\": \"I will\",\n",
        "  \"i'll've\": \"I will have\",\n",
        "  \"i'm\": \"I am\",\n",
        "  \"i've\": \"I have\",\n",
        "  \"isn't\": \"is not\",\n",
        "  \"it'd\": \"it had\",\n",
        "  \"it'd've\": \"it would have\",\n",
        "  \"it'll\": \"it will\",\n",
        "  \"it'll've\": \"it will have\",\n",
        "  \"it's\": \"it is\",\n",
        "  \"let's\": \"let us\",\n",
        "  \"ma'am\": \"madam\",\n",
        "  \"mayn't\": \"may not\",\n",
        "  \"mgr\": \"manager\",\n",
        "  \"might've\": \"might have\",\n",
        "  \"mightn't\": \"might not\",\n",
        "  \"mightn't've\": \"might not have\",\n",
        "  \"must've\": \"must have\",\n",
        "  \"mustn't\": \"must not\",\n",
        "  \"mustn't've\": \"must not have\",\n",
        "  \"needn't\": \"need not\",\n",
        "  \"needn't've\": \"need not have\",\n",
        "  \"o'clock\": \"of the clock\",\n",
        "  \"ofc\": \"office\",\n",
        "  \"oughtn't\": \"ought not\",\n",
        "  \"oughtn't've\": \"ought not have\",\n",
        "  \"pics\": \"pictures\",\n",
        "  \"shan't\": \"shall not\",\n",
        "  \"sha'n't\": \"shall not\",\n",
        "  \"shan't've\": \"shall not have\",\n",
        "  \"she'd\": \"she would\",\n",
        "  \"she'd've\": \"she would have\",\n",
        "  \"she'll\": \"she will\",\n",
        "  \"she'll've\": \"she will have\",\n",
        "  \"she's\": \"she is\",\n",
        "  \"should've\": \"should have\",\n",
        "  \"shouldn't\": \"should not\",\n",
        "  \"shouldn't've\": \"should not have\",\n",
        "  \"so've\": \"so have\",\n",
        "  \"so's\": \"so is\",\n",
        "  \"svc\":\"service\",\n",
        "  \"that'd\": \"that would\",\n",
        "  \"that'd've\": \"that would have\",\n",
        "  \"that's\": \"that is\",\n",
        "  \"there'd\": \"there had\",\n",
        "  \"there'd've\": \"there would have\",\n",
        "  \"there's\": \"there is\",\n",
        "  \"they'd\": \"they would\",\n",
        "  \"they'd've\": \"they would have\",\n",
        "  \"they'll\": \"they will\",\n",
        "  \"they'll've\": \"they will have\",\n",
        "  \"they're\": \"they are\",\n",
        "  \"they've\": \"they have\",\n",
        "  \"tho\":\"though\",\n",
        "  \"to've\": \"to have\",\n",
        "  \"wan na\": \"want to\",\n",
        "  \"wasn't\": \"was not\",\n",
        "  \"we'd\": \"we had\",\n",
        "  \"we'd've\": \"we would have\",\n",
        "  \"we'll\": \"we will\",\n",
        "  \"we'll've\": \"we will have\",\n",
        "  \"we're\": \"we are\",\n",
        "  \"we've\": \"we have\",\n",
        "  \"weren't\": \"were not\",\n",
        "  \"what'll\": \"what will\",\n",
        "  \"what'll've\": \"what will have\",\n",
        "  \"what're\": \"what are\",\n",
        "  \"what's\": \"what is\",\n",
        "  \"what've\": \"what have\",\n",
        "  \"when's\": \"when is\",\n",
        "  \"when've\": \"when have\",\n",
        "  \"where'd\": \"where did\",\n",
        "  \"where's\": \"where is\",\n",
        "  \"where've\": \"where have\",\n",
        "  \"who'll\": \"who will\",\n",
        "  \"who'll've\": \"who will have\",\n",
        "  \"who's\": \"who is\",\n",
        "  \"who've\": \"who have\",\n",
        "  \"why's\": \"why is\",\n",
        "  \"why've\": \"why have\",\n",
        "  \"will've\": \"will have\",\n",
        "  \"won't\": \"will not\",\n",
        "  \"won't've\": \"will not have\",\n",
        "  \"would've\": \"would have\",\n",
        "  \"wouldn't\": \"would not\",\n",
        "  \"wouldn't've\": \"would not have\",\n",
        "  \"y'all\": \"you all\",\n",
        "  \"y'alls\": \"you alls\",\n",
        "  \"y'all'd\": \"you all would\",\n",
        "  \"y'all'd've\": \"you all would have\",\n",
        "  \"y'all're\": \"you all are\",\n",
        "  \"y'all've\": \"you all have\",\n",
        "  \"you'd\": \"you had\",\n",
        "  \"you'd've\": \"you would have\",\n",
        "  \"you'll\": \"you you will\",\n",
        "  \"you'll've\": \"you you will have\",\n",
        "  \"you're\": \"you are\",\n",
        "  \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "\n",
        "def cont_to_exp(x):\n",
        "    if type(x) is str:\n",
        "        x = x.replace('\\\\','')\n",
        "        for key in contractions:\n",
        "            val = contractions[key]\n",
        "            x = x.replace(key,val)\n",
        "        return x\n",
        "    return x\n",
        "\n",
        "poltutrain['OCR'] = poltutrain['OCR'].apply(lambda x: x.lower())\n",
        "poltutrain['OCR'] = poltutrain['OCR'].apply(lambda x: cont_to_exp(x))\n",
        "poltutrain['OCR'] = poltutrain['OCR'].apply(lambda x: re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", x))\n",
        "\n",
        "\n",
        "\n",
        "poltuval['OCR'] = poltuval['OCR'].apply(lambda x: x.lower())\n",
        "poltuval['OCR'] = poltuval['OCR'].apply(lambda x: cont_to_exp(x))\n",
        "poltuval['OCR'] = poltuval['OCR'].apply(lambda x: re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", x))\n",
        "\n",
        "\n",
        "\n",
        "covidtrain['OCR'] = covidtrain['OCR'].apply(lambda x: x.lower())\n",
        "covidtrain['OCR'] = covidtrain['OCR'].apply(lambda x: cont_to_exp(x))\n",
        "covidtrain['OCR'] = covidtrain['OCR'].apply(lambda x: re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", x))\n",
        "\n",
        "\n",
        "\n",
        "covidval['OCR'] = covidval['OCR'].apply(lambda x: x.lower())\n",
        "covidval['OCR'] = covidval['OCR'].apply(lambda x: cont_to_exp(x))\n",
        "covidval['OCR'] = covidval['OCR'].apply(lambda x: re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", x))\n",
        "\n",
        "\n",
        "# traindata = traindata.sample(frac=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y_GTy7ZzL-N",
        "outputId": "c5edbf2d-8dde-4832-9401-81c38c09046e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                    text  category\n",
            "0      trump does he always just stand there like tha...         3\n",
            "1      trump does he always just stand there like tha...         3\n",
            "2      trump does he always just stand there like tha...         3\n",
            "3      welcome to the republican party where the poin...         2\n",
            "4      welcome to the republican party where the poin...         2\n",
            "...                                                  ...       ...\n",
            "17509  coronavirus intects tom hanks owator foloving ...         3\n",
            "17510  coronavirus intects tom hanks owator foloving ...         3\n",
            "17511  everybody 2020 is the year i ama travel corona...         3\n",
            "17512  everybody 2020 is the year i ama travel corona...         3\n",
            "17513  everybody 2020 is the year i ama travel corona...         3\n",
            "\n",
            "[17514 rows x 2 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\abhi2\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3460: FutureWarning: Could not cast to int32, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "poltutrainlabels = []\n",
        "poltutraintext = []\n",
        "\n",
        "\n",
        "\n",
        "for i in poltutrain.index:\n",
        "    sentence = poltutrain.iloc[i]['OCR']\n",
        "    hero = poltutrain.iloc[i]['hero']\n",
        "    victim = poltutrain.iloc[i]['victim']\n",
        "    villain = poltutrain.iloc[i]['villain']\n",
        "    other = poltutrain.iloc[i]['other']\n",
        "\n",
        "    for entity in hero:\n",
        "        poltutraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltutrainlabels.append(labels['hero'])\n",
        "\n",
        "    for entity in victim:\n",
        "        poltutraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltutrainlabels.append(labels['victim'])\n",
        "\n",
        "    for entity in villain:\n",
        "\n",
        "        poltutraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltutrainlabels.append(labels['villain'])\n",
        "\n",
        "    for entity in other:\n",
        "\n",
        "        poltutraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltutrainlabels.append(labels['other'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "covidtrainlabels = []\n",
        "covidtraintext = []\n",
        "\n",
        "\n",
        "\n",
        "for i in covidtrain.index:\n",
        "    sentence = covidtrain.iloc[i]['OCR']\n",
        "    hero = covidtrain.iloc[i]['hero']\n",
        "    victim = covidtrain.iloc[i]['victim']\n",
        "    villain = covidtrain.iloc[i]['villain']\n",
        "    other = covidtrain.iloc[i]['other']\n",
        "\n",
        "    for entity in hero:\n",
        "        covidtraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidtrainlabels.append(labels['hero'])\n",
        "\n",
        "    for entity in victim:\n",
        "        covidtraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidtrainlabels.append(labels['victim'])\n",
        "\n",
        "    for entity in villain:\n",
        "\n",
        "        covidtraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidtrainlabels.append(labels['villain'])\n",
        "\n",
        "    for entity in other:\n",
        "\n",
        "        covidtraintext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidtrainlabels.append(labels['other'])\n",
        "\n",
        "\n",
        "\n",
        "poltutraintext = [' '.join(i.split()) for i in poltutraintext]\n",
        "covidtraintext = [' '.join(i.split()) for i in covidtraintext]\n",
        "\n",
        "\n",
        "\n",
        "poltuvaltext = []\n",
        "poltuvallabels = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in poltuval.index:\n",
        "    sentence = poltuval.iloc[i]['OCR']\n",
        "    hero = poltuval.iloc[i]['hero']\n",
        "    victim = poltuval.iloc[i]['victim']\n",
        "    villain = poltuval.iloc[i]['villain']\n",
        "    other = poltuval.iloc[i]['other']\n",
        "\n",
        "    for entity in hero:\n",
        "        poltuvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltuvallabels.append(labels['hero'])\n",
        "\n",
        "    for entity in victim:\n",
        "        poltuvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltuvallabels.append(labels['victim'])\n",
        "\n",
        "    for entity in villain:\n",
        "        poltuvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltuvallabels.append(labels['villain'])\n",
        "\n",
        "    for entity in other:\n",
        "        poltuvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        poltuvallabels.append(labels['other'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "covidvaltext = []\n",
        "covidvallabels = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in covidval.index:\n",
        "    sentence = covidval.iloc[i]['OCR']\n",
        "    hero = covidval.iloc[i]['hero']\n",
        "    victim = covidval.iloc[i]['victim']\n",
        "    villain = covidval.iloc[i]['villain']\n",
        "    other = covidval.iloc[i]['other']\n",
        "\n",
        "    for entity in hero:\n",
        "        covidvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidvallabels.append(labels['hero'])\n",
        "\n",
        "    for entity in victim:\n",
        "        covidvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidvallabels.append(labels['victim'])\n",
        "\n",
        "    for entity in villain:\n",
        "        covidvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidvallabels.append(labels['villain'])\n",
        "\n",
        "    for entity in other:\n",
        "        covidvaltext.append(sentence + ' [SEP] ' + entity.lower())\n",
        "        covidvallabels.append(labels['other'])\n",
        "\n",
        "\n",
        "poltuvaltext = [' '.join(i.split()) for i in poltuvaltext]\n",
        "covidvaltext = [' '.join(i.split()) for i in covidvaltext]\n",
        "\n",
        "\n",
        "poltutraintext.extend(covidtraintext)\n",
        "poltutrainlabels.extend(covidtrainlabels)\n",
        "\n",
        "poltuvaltext.extend(covidvaltext)\n",
        "poltuvallabels.extend(covidvallabels)\n",
        "\n",
        "nettrain = [[poltutraintext[i],poltutrainlabels[i]] for i in range(len(poltutrainlabels))]\n",
        "traindf = pd.DataFrame(nettrain,columns=['text','category'],dtype=int)\n",
        "traindf = traindf.sample(frac=1,random_state=42)\n",
        "\n",
        "\n",
        "netval = [[poltuvaltext[i],poltuvallabels[i]] for i in range(len(poltuvallabels))]\n",
        "valdf = pd.DataFrame(netval,columns=['text','category'],dtype=int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ytCW-7o6zNbR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [label for label in df['category']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oPqFS4AWzO4S"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import RobertaForSequenceClassification\n",
        "\n",
        "\n",
        "\n",
        "# class RoBertaClassifier(nn.Module):\n",
        "\n",
        "#     def __init__(self, dropout=0.5):\n",
        "\n",
        "#         super(RoBertaClassifier, self).__init__()\n",
        "\n",
        "#         self.bert = RobertaModel.from_pretrained('roberta-base')\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         self.linear = nn.Linear(768, 4)\n",
        "#         self.relu = nn.ReLU()\n",
        "\n",
        "#     def forward(self, input_id, mask):\n",
        "\n",
        "#         _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "#         dropout_output = self.dropout(pooled_output)\n",
        "#         linear_output = self.linear(dropout_output)\n",
        "#         final_layer = self.relu(linear_output)\n",
        "\n",
        "#         return final_layer\n",
        "\n",
        "\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\", num_labels=4, problem_type=\"multi_label_classification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXv_3uYrzQIL",
        "outputId": "ddeaafbd-8e86-4fcc-9bff-0c50ddd9972d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 505/7524 [04:13<58:36,  2.00it/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m LR \u001b[39m=\u001b[39m \u001b[39m1e-5\u001b[39m\n\u001b[0;32m     75\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> 76\u001b[0m train(model, traindf, valdf, LR, EPOCHS)\n",
            "Cell \u001b[1;32mIn[24], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     43\u001b[0m     model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     44\u001b[0m     batch_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 45\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     47\u001b[0m total_acc_val \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     48\u001b[0m total_loss_val \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\abhi2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[1;32mc:\\Users\\abhi2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[1;32mc:\\Users\\abhi2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    235\u001b[0m          grads,\n\u001b[0;32m    236\u001b[0m          exp_avgs,\n\u001b[0;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    239\u001b[0m          state_steps,\n\u001b[0;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[0;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
            "File \u001b[1;32mc:\\Users\\abhi2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m func(params,\n\u001b[0;32m    301\u001b[0m      grads,\n\u001b[0;32m    302\u001b[0m      exp_avgs,\n\u001b[0;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    305\u001b[0m      state_steps,\n\u001b[0;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
            "File \u001b[1;32mc:\\Users\\abhi2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:364\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    363\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[1;32m--> 364\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n\u001b[0;32m    367\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask).logits\n",
        "                # predicted_class_ids = [torch.sigmoid(logits).squeeze(dim=0) > 0.5]\n",
        "                # output = torch.sum(torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=4), dim=1).to(torch.float)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask).logits\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "              \n",
        "\n",
        "\n",
        "LR = 1e-5\n",
        "EPOCHS = 2\n",
        "train(model, traindf, valdf, LR, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1o8SIqHzSeF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def fscores(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        totalout = []\n",
        "        totalpred = []\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask).logits\n",
        "              output = output.argmax(dim=1)\n",
        "\n",
        "              totalout.extend(test_label.cpu())\n",
        "              totalpred.extend(output.cpu())\n",
        "    \n",
        "    print(\"Micro F1 score: \", f1_score(totalout, totalpred, average=\"micro\"))\n",
        "    print(\"Macro F1 score: \", f1_score(totalout, totalpred, average=\"macro\"))\n",
        "    print(\"Average F1 score: \", (f1_score(totalout, totalpred,average=\"micro\") + f1_score(totalout, totalpred, average=\"macro\")) / 2)\n",
        "    \n",
        "\n",
        "print(\"Validation Data F1 Scores\")\n",
        "fscores(model,valdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJBbvfxbzS_s"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"model_roberta_seq.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "torch.save(obj=model.state_dict(), f = MODEL_SAVE_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
